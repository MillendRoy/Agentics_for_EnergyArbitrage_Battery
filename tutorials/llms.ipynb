{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using LLMs\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of various Large Language Model (LLM) providers and tools for natural language processing tasks. It showcases how to interact with LLMs using the `crewai` library (which is used by Agentics), parse structured outputs with Pydantic models, and explore available LLM connections. The notebook provides practical examples for calling different LLMs, formatting responses, and integrating with external providers such as OpenAI and IBM WatsonX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62180815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/gliozzo/Code/agentics911/agentics/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 18ms\u001b[0m\u001b[0m\n",
      "In Colab: False\n"
     ]
    }
   ],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
    "else:\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Connect to your own LLM provider\n",
    "Agentics uses CrewAI wrappers for main LLM providers. You can initialize your LLM as follows.\n",
    "[find out more](https://docs.crewai.com/en/concepts/llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec92f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<crewai.llm.LLM object at 0x11f8769c0>\n"
     ]
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# pick a provider (openai, anthropic, groq, etc.) - see crewai docs for details\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7,  # Adjust based on task\n",
    "    max_tokens=4096,  # Set based on output needs\n",
    "    timeout=300,\n",
    ")  # Longer timeout for complex tasks\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Perform Simple LLM call\n",
    "\n",
    "Once an LLM is instatiated, you can perform LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab039e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is located in **Paris, France**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm.call(\"where is the Eiffel Tower?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Perform Structured Call\n",
    "\n",
    "LLMs can generate structured objects given a pydantic schema if you instantiate them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984913a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"short_answer\": \"The sky is blue due to a phenomenon called Rayleigh scattering.\",\n",
      "  \"detailed_answer\": \"Rayleigh scattering is the scattering of electromagnetic radiation (including visible light) by particles of a much smaller wavelength. In Earth's atmosphere, sunlight is scattered by small molecules like nitrogen and oxygen. Blue light is scattered more strongly than other colors because it travels as shorter, smaller waves. This is why when we look up, we see the scattered blue light from all directions, making the sky appear blue. At sunrise and sunset, the light has to travel through more of the atmosphere, so more of the blue light is scattered away, leaving the longer wavelengths like red and orange to dominate.\",\n",
      "  \"confidence\": 0.95\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    short_answer: str\n",
    "    detailed_answer: str\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "struct_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=Answer)\n",
    "\n",
    "print(struct_llm.call(\"Why is the sky blue?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## You can also use structured decoding for information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8c2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"books\": [\n",
      "    {\n",
      "      \"title\": \"Tractatus Logico-Philosophicus\",\n",
      "      \"publisher\": \"Routledge and Kegan Paul\",\n",
      "      \"year\": 1961,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Philosophical Investigations\",\n",
      "      \"publisher\": \"Basil Blackwell\",\n",
      "      \"year\": 1963,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"On Certainty\",\n",
      "      \"publisher\": \"Basil Blackwell\",\n",
      "      \"year\": 1979,\n",
      "      \"author\": {\n",
      "        \"name\": \"Ludwig Wittgenstein\",\n",
      "        \"city\": \"Vienna\",\n",
      "        \"occupation\": \"Philosopher\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"people\": [\n",
      "    {\n",
      "      \"name\": \"Ludwig Wittgenstein\",\n",
      "      \"city\": \"Vienna\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Bertrand Russell\",\n",
      "      \"city\": \"Cambridge\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Gottlob Frege\",\n",
      "      \"city\": \"Wismar\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Arthur Schopenhauer\",\n",
      "      \"city\": \"Gdansk\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Immanuel Kant\",\n",
      "      \"city\": \"Königsberg\",\n",
      "      \"occupation\": \"Philosopher\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    city: str\n",
    "    occupation: str\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    publisher: str\n",
    "    year: int\n",
    "    author: Person\n",
    "\n",
    "\n",
    "class InformationExtraction(BaseModel):\n",
    "    books: list[Book]\n",
    "    people: list[Person]\n",
    "\n",
    "\n",
    "person_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=InformationExtraction)\n",
    "print(person_llm.call(requests.get(\"https://iep.utm.edu/wittgens/\").text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Using Agentics Predefined LLMs\n",
    "\n",
    "Agentics has the following LLM handles: watsonx_llm, openai_llm, gemini_llm\n",
    "You can directly import and use them as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b95374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'watsonx': <crewai.llm.LLM object at 0x1556a6c00>, 'gemini': <crewai.llm.LLM object at 0x1545e48f0>, 'openai': <crewai.llm.LLM object at 0x15600b080>}\n",
      "Rome is the capital city of Italy. It lies in the central‑western part of the Italian Peninsula, on the banks of the Tiber River. Geographically, its coordinates are approximately **41.90° N latitude** and **12.48° E longitude**. The city is situated in the region of **Lazio**, about 24 km (15 mi) inland from the Tyrrhenian Sea.\n",
      "Rome is the capital city of **Italy**. It's located in the central-western part of the Italian Peninsula, along the Tiber River.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agentics import AG\n",
    "print(AG.get_llm_provider(\"list\"))\n",
    "\n",
    "llm=AG.get_llm_provider() ## get the default LLM provider from the available ones\n",
    "print(llm.call(\"Where is Rome?\"))\n",
    "\n",
    "llm=AG.get_llm_provider(\"gemini\") ## get a specific LLM provider from the available ones,change \"gemini\" with \"openai\", \"watsonx\", etc. as needed\n",
    "print(llm.call(\"Where is Rome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Play with different data models on your favourite domain (e.g. stocks) providing relevant data. Enjoy tructured decoding magic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
