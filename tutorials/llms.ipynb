{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Using LLMs\n",
    "\n",
    "This Jupyter Notebook demonstrates the use of various Large Language Model (LLM) providers and tools for natural language processing tasks. It showcases how to interact with LLMs using the `crewai` library (which is used by Agentics), parse structured outputs with Pydantic models, and explore available LLM connections. The notebook provides practical examples for calling different LLMs, formatting responses, and integrating with external providers such as OpenAI and IBM WatsonX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62180815",
   "metadata": {},
   "outputs": [],
   "source": [
    "! uv pip install agentics-py\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "CURRENT_PATH = \"\"\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "print(\"In Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    CURRENT_PATH = \"/content/drive/MyDrive/\"\n",
    "    # Mount your google drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    from google.colab import userdata\n",
    "\n",
    "    os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")\n",
    "else:\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Connect to your own LLM provider\n",
    "Agentics uses CrewAI wrappers for main LLM providers. You can initialize your LLM as follows.\n",
    "[find out more](https://docs.crewai.com/en/concepts/llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec92f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "# pick a provider (openai, anthropic, groq, etc.) - see crewai docs for details\n",
    "llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7,  # Adjust based on task\n",
    "    max_tokens=4096,  # Set based on output needs\n",
    "    timeout=300,\n",
    ")  # Longer timeout for complex tasks\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Perform Simple LLM call\n",
    "\n",
    "Once an LLM is instatiated, you can perform LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab039e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm.call(\"where is the Eiffel Tower?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Perform Structured Call\n",
    "\n",
    "LLMs can generate structured objects given a pydantic schema if you instantiate them accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984913a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    short_answer: str\n",
    "    detailed_answer: str\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "struct_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=Answer)\n",
    "\n",
    "print(struct_llm.call(\"Why is the sky blue?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## You can also use structured decoding for information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    city: str\n",
    "    occupation: str\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    publisher: str\n",
    "    year: int\n",
    "    author: Person\n",
    "\n",
    "\n",
    "class InformationExtraction(BaseModel):\n",
    "    books: list[Book]\n",
    "    people: list[Person]\n",
    "\n",
    "\n",
    "person_llm = LLM(model=\"gemini/gemini-2.0-flash\", response_format=InformationExtraction)\n",
    "print(person_llm.call(requests.get(\"https://iep.utm.edu/wittgens/\").text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Using Agentics Predefined LLMs\n",
    "\n",
    "Agentics has the following LLM handles: watsonx_llm, openai_llm, gemini_llm\n",
    "You can directly import and use them as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b95374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentics import AG\n",
    "\n",
    "print(AG.get_llm_provider(\"list\"))\n",
    "\n",
    "llm = AG.get_llm_provider()  ## get the default LLM provider from the available ones\n",
    "print(llm.call(\"Where is Rome?\"))\n",
    "\n",
    "llm = AG.get_llm_provider(\n",
    "    \"gemini\"\n",
    ")  ## get a specific LLM provider from the available ones,change \"gemini\" with \"openai\", \"watsonx\", etc. as needed\n",
    "print(llm.call(\"Where is Rome?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Play with different data models on your favourite domain (e.g. stocks) providing relevant data. Enjoy tructured decoding magic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
